{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cad13b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ca4bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Algerian_forest_fires_cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1972287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 15)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27311bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Classes'] =  data['Classes'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69829648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.0</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.761317</td>\n",
       "      <td>7.502058</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>32.152263</td>\n",
       "      <td>62.041152</td>\n",
       "      <td>15.493827</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>77.842387</td>\n",
       "      <td>14.680658</td>\n",
       "      <td>49.430864</td>\n",
       "      <td>4.742387</td>\n",
       "      <td>16.690535</td>\n",
       "      <td>7.035391</td>\n",
       "      <td>0.497942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.842552</td>\n",
       "      <td>1.114793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.628039</td>\n",
       "      <td>14.828160</td>\n",
       "      <td>2.811385</td>\n",
       "      <td>2.003207</td>\n",
       "      <td>14.349641</td>\n",
       "      <td>12.393040</td>\n",
       "      <td>47.665606</td>\n",
       "      <td>4.154234</td>\n",
       "      <td>14.228421</td>\n",
       "      <td>7.440568</td>\n",
       "      <td>0.501028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.850000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.300000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>88.300000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>69.100000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>22.650000</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>65.900000</td>\n",
       "      <td>220.400000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              day       month    year  Temperature          RH          Ws  \\\n",
       "count  243.000000  243.000000   243.0   243.000000  243.000000  243.000000   \n",
       "mean    15.761317    7.502058  2012.0    32.152263   62.041152   15.493827   \n",
       "std      8.842552    1.114793     0.0     3.628039   14.828160    2.811385   \n",
       "min      1.000000    6.000000  2012.0    22.000000   21.000000    6.000000   \n",
       "25%      8.000000    7.000000  2012.0    30.000000   52.500000   14.000000   \n",
       "50%     16.000000    8.000000  2012.0    32.000000   63.000000   15.000000   \n",
       "75%     23.000000    8.000000  2012.0    35.000000   73.500000   17.000000   \n",
       "max     31.000000    9.000000  2012.0    42.000000   90.000000   29.000000   \n",
       "\n",
       "             Rain        FFMC         DMC          DC         ISI         BUI  \\\n",
       "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
       "mean     0.762963   77.842387   14.680658   49.430864    4.742387   16.690535   \n",
       "std      2.003207   14.349641   12.393040   47.665606    4.154234   14.228421   \n",
       "min      0.000000   28.600000    0.700000    6.900000    0.000000    1.100000   \n",
       "25%      0.000000   71.850000    5.800000   12.350000    1.400000    6.000000   \n",
       "50%      0.000000   83.300000   11.300000   33.100000    3.500000   12.400000   \n",
       "75%      0.500000   88.300000   20.800000   69.100000    7.250000   22.650000   \n",
       "max     16.800000   96.000000   65.900000  220.400000   19.000000   68.000000   \n",
       "\n",
       "              FWI      Region  \n",
       "count  243.000000  243.000000  \n",
       "mean     7.035391    0.497942  \n",
       "std      7.440568    0.501028  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.700000    0.000000  \n",
       "50%      4.200000    0.000000  \n",
       "75%     11.450000    1.000000  \n",
       "max     31.100000    1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9045ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>Classes</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>not fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>not fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>not fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>fire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>4.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>not fire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>not fire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>not fire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  year  Temperature  RH  Ws  Rain  FFMC   DMC    DC  ISI   BUI  \\\n",
       "0      1      6  2012           29  57  18   0.0  65.7   3.4   7.6  1.3   3.4   \n",
       "1      2      6  2012           29  61  13   1.3  64.4   4.1   7.6  1.0   3.9   \n",
       "2      3      6  2012           26  82  22  13.1  47.1   2.5   7.1  0.3   2.7   \n",
       "3      4      6  2012           25  89  13   2.5  28.6   1.3   6.9  0.0   1.7   \n",
       "4      5      6  2012           27  77  16   0.0  64.8   3.0  14.2  1.2   3.9   \n",
       "..   ...    ...   ...          ...  ..  ..   ...   ...   ...   ...  ...   ...   \n",
       "238   26      9  2012           30  65  14   0.0  85.4  16.0  44.5  4.5  16.9   \n",
       "239   27      9  2012           28  87  15   4.4  41.1   6.5   8.0  0.1   6.2   \n",
       "240   28      9  2012           27  87  29   0.5  45.9   3.5   7.9  0.4   3.4   \n",
       "241   29      9  2012           24  54  18   0.1  79.7   4.3  15.2  1.7   5.1   \n",
       "242   30      9  2012           24  64  15   0.2  67.3   3.8  16.5  1.2   4.8   \n",
       "\n",
       "     FWI   Classes  Region  \n",
       "0    0.5  not fire       0  \n",
       "1    0.4  not fire       0  \n",
       "2    0.1  not fire       0  \n",
       "3    0.0  not fire       0  \n",
       "4    0.5  not fire       0  \n",
       "..   ...       ...     ...  \n",
       "238  6.5      fire       1  \n",
       "239  0.0  not fire       1  \n",
       "240  0.2  not fire       1  \n",
       "241  0.7  not fire       1  \n",
       "242  0.5  not fire       1  \n",
       "\n",
       "[243 rows x 15 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b88fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Classes'] = data['Classes'].apply(lambda x: 0 if x == \"not fire\" else 1 if x ==\"fire\" else 2)\n",
    "# data['Classes'] = data['Classes'].apply('fire', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d7a2541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>Classes</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>4.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  year  Temperature  RH  Ws  Rain  FFMC   DMC    DC  ISI   BUI  \\\n",
       "0      1      6  2012           29  57  18   0.0  65.7   3.4   7.6  1.3   3.4   \n",
       "1      2      6  2012           29  61  13   1.3  64.4   4.1   7.6  1.0   3.9   \n",
       "2      3      6  2012           26  82  22  13.1  47.1   2.5   7.1  0.3   2.7   \n",
       "3      4      6  2012           25  89  13   2.5  28.6   1.3   6.9  0.0   1.7   \n",
       "4      5      6  2012           27  77  16   0.0  64.8   3.0  14.2  1.2   3.9   \n",
       "..   ...    ...   ...          ...  ..  ..   ...   ...   ...   ...  ...   ...   \n",
       "238   26      9  2012           30  65  14   0.0  85.4  16.0  44.5  4.5  16.9   \n",
       "239   27      9  2012           28  87  15   4.4  41.1   6.5   8.0  0.1   6.2   \n",
       "240   28      9  2012           27  87  29   0.5  45.9   3.5   7.9  0.4   3.4   \n",
       "241   29      9  2012           24  54  18   0.1  79.7   4.3  15.2  1.7   5.1   \n",
       "242   30      9  2012           24  64  15   0.2  67.3   3.8  16.5  1.2   4.8   \n",
       "\n",
       "     FWI  Classes  Region  \n",
       "0    0.5        0       0  \n",
       "1    0.4        0       0  \n",
       "2    0.1        0       0  \n",
       "3    0.0        0       0  \n",
       "4    0.5        0       0  \n",
       "..   ...      ...     ...  \n",
       "238  6.5        1       1  \n",
       "239  0.0        0       1  \n",
       "240  0.2        0       1  \n",
       "241  0.7        0       1  \n",
       "242  0.5        0       1  \n",
       "\n",
       "[243 rows x 15 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83cab83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 243\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "  \n",
    "    print(\"Number of rows in the dataset:\", len(data))\n",
    "    \n",
    "    if data.empty:\n",
    "        print(\"The dataset is empty.\")\n",
    "    else:\n",
    "        selected_columns = ['day', 'month', 'year', 'Temperature', 'Rain', 'RH', 'Classes']\n",
    "        data = data[selected_columns]\n",
    "        if len(data) > 0:\n",
    "            X = data.drop('Classes', axis=1)\n",
    "            y = data['Classes'] \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        else:\n",
    "            print(\"Not enough samples to split the data.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please provide the correct file path.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77ad8d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     day  month  year  Temperature  Rain  RH  Classes\n",
      "0      1      6  2012           29   0.0  57        0\n",
      "1      2      6  2012           29   1.3  61        0\n",
      "2      3      6  2012           26  13.1  82        0\n",
      "3      4      6  2012           25   2.5  89        0\n",
      "4      5      6  2012           27   0.0  77        0\n",
      "..   ...    ...   ...          ...   ...  ..      ...\n",
      "238   26      9  2012           30   0.0  65        1\n",
      "239   27      9  2012           28   4.4  87        0\n",
      "240   28      9  2012           27   0.5  87        0\n",
      "241   29      9  2012           24   0.1  54        0\n",
      "242   30      9  2012           24   0.2  64        0\n",
      "\n",
      "[243 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84706c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35e3f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),  # Add batch normalization for better convergence\n",
    "    Dropout(0.6),  # Add dropout regularization to prevent overfitting\n",
    "    Dense(32, activation='relu'),  # Increase the number of neurons in the hidden layer\n",
    "    BatchNormalization(),  # Add batch normalization for better convergence\n",
    "    Dropout(0.5),  # Add dropout regularization to prevent overfitting\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer='adam',  # Use Adam optimizer\n",
    "#               loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer='rmsprop',  # Use RMSprop optimizer\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adagrad',  # Use Adagrad optimizer\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # Print model summary\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38a35594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 70ms/step - loss: 0.9689 - accuracy: 0.5161 - val_loss: 89.4966 - val_accuracy: 0.5385\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0710 - accuracy: 0.4452 - val_loss: 82.2818 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0296 - accuracy: 0.5290 - val_loss: 76.6239 - val_accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8731 - accuracy: 0.5290 - val_loss: 70.3994 - val_accuracy: 0.5385\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0683 - accuracy: 0.4645 - val_loss: 65.0463 - val_accuracy: 0.5385\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0341 - accuracy: 0.4903 - val_loss: 60.1599 - val_accuracy: 0.5385\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8159 - accuracy: 0.6129 - val_loss: 55.5142 - val_accuracy: 0.5385\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9828 - accuracy: 0.5097 - val_loss: 51.0678 - val_accuracy: 0.5385\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0053 - accuracy: 0.4839 - val_loss: 47.0467 - val_accuracy: 0.5385\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9700 - accuracy: 0.4839 - val_loss: 43.5421 - val_accuracy: 0.5385\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9449 - accuracy: 0.5161 - val_loss: 40.9312 - val_accuracy: 0.5385\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0077 - accuracy: 0.5419 - val_loss: 38.5043 - val_accuracy: 0.5385\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9078 - accuracy: 0.5484 - val_loss: 36.0517 - val_accuracy: 0.5385\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8865 - accuracy: 0.5032 - val_loss: 33.3040 - val_accuracy: 0.5385\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9634 - accuracy: 0.5613 - val_loss: 31.0527 - val_accuracy: 0.5385\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8786 - accuracy: 0.5355 - val_loss: 28.7476 - val_accuracy: 0.5385\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9711 - accuracy: 0.5161 - val_loss: 26.8704 - val_accuracy: 0.5385\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9760 - accuracy: 0.4968 - val_loss: 25.0469 - val_accuracy: 0.5385\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8801 - accuracy: 0.6065 - val_loss: 23.5001 - val_accuracy: 0.5385\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7902 - accuracy: 0.6065 - val_loss: 22.2390 - val_accuracy: 0.5385\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9107 - accuracy: 0.5290 - val_loss: 21.0163 - val_accuracy: 0.5385\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7534 - accuracy: 0.6065 - val_loss: 19.7704 - val_accuracy: 0.5385\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7940 - accuracy: 0.6258 - val_loss: 18.7398 - val_accuracy: 0.5385\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9521 - accuracy: 0.4710 - val_loss: 17.6735 - val_accuracy: 0.5385\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8960 - accuracy: 0.5419 - val_loss: 16.7073 - val_accuracy: 0.5385\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7878 - accuracy: 0.5742 - val_loss: 15.9692 - val_accuracy: 0.5385\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8629 - accuracy: 0.5484 - val_loss: 15.1227 - val_accuracy: 0.5385\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8088 - accuracy: 0.5871 - val_loss: 14.2464 - val_accuracy: 0.5385\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8541 - accuracy: 0.6258 - val_loss: 13.3597 - val_accuracy: 0.5385\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0283 - accuracy: 0.4645 - val_loss: 12.6848 - val_accuracy: 0.5385\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8140 - accuracy: 0.6452 - val_loss: 12.0868 - val_accuracy: 0.5385\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8732 - accuracy: 0.5419 - val_loss: 11.3692 - val_accuracy: 0.5385\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8643 - accuracy: 0.5484 - val_loss: 10.6048 - val_accuracy: 0.5385\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7881 - accuracy: 0.6065 - val_loss: 10.0849 - val_accuracy: 0.5385\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8007 - accuracy: 0.6581 - val_loss: 9.7308 - val_accuracy: 0.5385\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8740 - accuracy: 0.5419 - val_loss: 9.3287 - val_accuracy: 0.5385\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8314 - accuracy: 0.6065 - val_loss: 8.8531 - val_accuracy: 0.5385\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8227 - accuracy: 0.5613 - val_loss: 8.3053 - val_accuracy: 0.5385\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7763 - accuracy: 0.5290 - val_loss: 7.7899 - val_accuracy: 0.5385\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7468 - accuracy: 0.6323 - val_loss: 7.3257 - val_accuracy: 0.5385\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7912 - accuracy: 0.5742 - val_loss: 6.9937 - val_accuracy: 0.5385\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7457 - accuracy: 0.5742 - val_loss: 6.5889 - val_accuracy: 0.5385\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7768 - accuracy: 0.6194 - val_loss: 6.1968 - val_accuracy: 0.5385\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7433 - accuracy: 0.6065 - val_loss: 5.9184 - val_accuracy: 0.5385\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8296 - accuracy: 0.6065 - val_loss: 5.6116 - val_accuracy: 0.5385\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9667 - accuracy: 0.4968 - val_loss: 5.2412 - val_accuracy: 0.5385\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7444 - accuracy: 0.6258 - val_loss: 4.9235 - val_accuracy: 0.5385\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7510 - accuracy: 0.6387 - val_loss: 4.6898 - val_accuracy: 0.5385\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7561 - accuracy: 0.6452 - val_loss: 4.4419 - val_accuracy: 0.5385\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7537 - accuracy: 0.5806 - val_loss: 4.1120 - val_accuracy: 0.5385\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8349 - accuracy: 0.6000 - val_loss: 3.9161 - val_accuracy: 0.5385\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8325 - accuracy: 0.5806 - val_loss: 3.6958 - val_accuracy: 0.5385\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8003 - accuracy: 0.5935 - val_loss: 3.4968 - val_accuracy: 0.5385\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7701 - accuracy: 0.6258 - val_loss: 3.2573 - val_accuracy: 0.5385\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.6516 - val_loss: 3.0508 - val_accuracy: 0.5385\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8344 - accuracy: 0.5355 - val_loss: 2.8837 - val_accuracy: 0.5385\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7777 - accuracy: 0.6000 - val_loss: 2.7156 - val_accuracy: 0.5385\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7831 - accuracy: 0.6065 - val_loss: 2.5601 - val_accuracy: 0.5385\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9635 - accuracy: 0.5161 - val_loss: 2.4012 - val_accuracy: 0.5385\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8676 - accuracy: 0.5548 - val_loss: 2.2427 - val_accuracy: 0.5385\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8284 - accuracy: 0.5355 - val_loss: 2.0919 - val_accuracy: 0.5385\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8392 - accuracy: 0.6000 - val_loss: 1.9729 - val_accuracy: 0.5385\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7276 - accuracy: 0.6129 - val_loss: 1.8509 - val_accuracy: 0.5385\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8005 - accuracy: 0.5613 - val_loss: 1.7132 - val_accuracy: 0.5385\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7163 - accuracy: 0.6258 - val_loss: 1.6249 - val_accuracy: 0.5385\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8818 - accuracy: 0.5677 - val_loss: 1.5433 - val_accuracy: 0.5385\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8405 - accuracy: 0.5548 - val_loss: 1.4692 - val_accuracy: 0.5385\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7718 - accuracy: 0.5419 - val_loss: 1.3932 - val_accuracy: 0.5385\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7694 - accuracy: 0.6581 - val_loss: 1.3097 - val_accuracy: 0.5641\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8227 - accuracy: 0.5613 - val_loss: 1.2478 - val_accuracy: 0.5641\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7036 - accuracy: 0.6065 - val_loss: 1.1795 - val_accuracy: 0.5641\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8768 - accuracy: 0.5871 - val_loss: 1.0968 - val_accuracy: 0.5897\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7643 - accuracy: 0.6000 - val_loss: 1.0402 - val_accuracy: 0.6154\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8170 - accuracy: 0.5742 - val_loss: 0.9896 - val_accuracy: 0.6154\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7782 - accuracy: 0.6387 - val_loss: 0.9335 - val_accuracy: 0.6154\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7218 - accuracy: 0.6387 - val_loss: 0.8912 - val_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8072 - accuracy: 0.6258 - val_loss: 0.8555 - val_accuracy: 0.6923\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7247 - accuracy: 0.5871 - val_loss: 0.8189 - val_accuracy: 0.7179\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8267 - accuracy: 0.6452 - val_loss: 0.7819 - val_accuracy: 0.7179\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7257 - accuracy: 0.6387 - val_loss: 0.7470 - val_accuracy: 0.7179\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8166 - accuracy: 0.6258 - val_loss: 0.7296 - val_accuracy: 0.7179\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7295 - accuracy: 0.6387 - val_loss: 0.7092 - val_accuracy: 0.7179\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7939 - accuracy: 0.5548 - val_loss: 0.6879 - val_accuracy: 0.7179\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8743 - accuracy: 0.5677 - val_loss: 0.6665 - val_accuracy: 0.7179\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6772 - accuracy: 0.6710 - val_loss: 0.6493 - val_accuracy: 0.7179\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8181 - accuracy: 0.6000 - val_loss: 0.6287 - val_accuracy: 0.7179\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7476 - accuracy: 0.6065 - val_loss: 0.6107 - val_accuracy: 0.7179\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8539 - accuracy: 0.5355 - val_loss: 0.5962 - val_accuracy: 0.7179\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7313 - accuracy: 0.6452 - val_loss: 0.5848 - val_accuracy: 0.7179\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7623 - accuracy: 0.6000 - val_loss: 0.5736 - val_accuracy: 0.7179\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6322 - accuracy: 0.7355 - val_loss: 0.5679 - val_accuracy: 0.7179\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7342 - accuracy: 0.6065 - val_loss: 0.5576 - val_accuracy: 0.7179\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7886 - accuracy: 0.5935 - val_loss: 0.5506 - val_accuracy: 0.7179\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7759 - accuracy: 0.6129 - val_loss: 0.5426 - val_accuracy: 0.7436\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8776 - accuracy: 0.5613 - val_loss: 0.5364 - val_accuracy: 0.7692\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6985 - accuracy: 0.6581 - val_loss: 0.5301 - val_accuracy: 0.7436\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7159 - accuracy: 0.6387 - val_loss: 0.5305 - val_accuracy: 0.7436\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7534 - accuracy: 0.6129 - val_loss: 0.5206 - val_accuracy: 0.7436\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7535 - accuracy: 0.6516 - val_loss: 0.5204 - val_accuracy: 0.7436\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7043 - accuracy: 0.6516 - val_loss: 0.5182 - val_accuracy: 0.7436\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Test Accuracy:  0.673469387755102\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62        22\n",
      "           1       0.69      0.74      0.71        27\n",
      "\n",
      "    accuracy                           0.67        49\n",
      "   macro avg       0.67      0.67      0.67        49\n",
      "weighted avg       0.67      0.67      0.67        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"Test Accuracy: \", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e44ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "# Define input layer\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Define hidden layers\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Define output layer\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adagrad',  # Use Adagrad optimizer\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee15fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 59ms/step - loss: 144.1271 - accuracy: 0.5161 - val_loss: 34.5973 - val_accuracy: 0.5385\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 125.4947 - accuracy: 0.5226 - val_loss: 30.5695 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 121.5636 - accuracy: 0.5355 - val_loss: 28.4197 - val_accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 130.9317 - accuracy: 0.4581 - val_loss: 24.5211 - val_accuracy: 0.5385\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 111.8708 - accuracy: 0.5484 - val_loss: 21.5662 - val_accuracy: 0.5385\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 121.9101 - accuracy: 0.5290 - val_loss: 18.6725 - val_accuracy: 0.5385\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 112.7715 - accuracy: 0.5548 - val_loss: 17.4724 - val_accuracy: 0.5385\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 117.1259 - accuracy: 0.5355 - val_loss: 16.5298 - val_accuracy: 0.5385\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 103.5643 - accuracy: 0.5548 - val_loss: 14.6415 - val_accuracy: 0.5385\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 111.3867 - accuracy: 0.5484 - val_loss: 13.4924 - val_accuracy: 0.5385\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 105.2820 - accuracy: 0.5742 - val_loss: 12.1607 - val_accuracy: 0.5385\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 135.4744 - accuracy: 0.4645 - val_loss: 12.3153 - val_accuracy: 0.5385\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 101.7072 - accuracy: 0.5355 - val_loss: 11.7148 - val_accuracy: 0.5385\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 118.4975 - accuracy: 0.5548 - val_loss: 11.9652 - val_accuracy: 0.5385\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 94.4439 - accuracy: 0.5677 - val_loss: 10.2299 - val_accuracy: 0.5385\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 119.2975 - accuracy: 0.4903 - val_loss: 8.3090 - val_accuracy: 0.5385\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 100.2963 - accuracy: 0.5548 - val_loss: 7.1604 - val_accuracy: 0.5385\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 102.1971 - accuracy: 0.5355 - val_loss: 7.7123 - val_accuracy: 0.5385\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 105.7585 - accuracy: 0.4903 - val_loss: 6.9849 - val_accuracy: 0.5385\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 102.4532 - accuracy: 0.5613 - val_loss: 5.8458 - val_accuracy: 0.5385\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 101.7018 - accuracy: 0.4839 - val_loss: 7.2536 - val_accuracy: 0.5385\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 106.0690 - accuracy: 0.5097 - val_loss: 6.4489 - val_accuracy: 0.5385\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 87.3969 - accuracy: 0.5548 - val_loss: 6.4634 - val_accuracy: 0.5385\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 104.4356 - accuracy: 0.5097 - val_loss: 6.7373 - val_accuracy: 0.5385\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 132.9692 - accuracy: 0.4839 - val_loss: 6.3938 - val_accuracy: 0.5385\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 91.7578 - accuracy: 0.5226 - val_loss: 7.1000 - val_accuracy: 0.5385\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 116.0385 - accuracy: 0.4839 - val_loss: 7.5207 - val_accuracy: 0.5385\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 95.3822 - accuracy: 0.5290 - val_loss: 7.2323 - val_accuracy: 0.5385\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 97.5711 - accuracy: 0.5226 - val_loss: 7.1129 - val_accuracy: 0.5385\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 94.7808 - accuracy: 0.5419 - val_loss: 7.2774 - val_accuracy: 0.5385\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 108.7118 - accuracy: 0.5161 - val_loss: 7.5986 - val_accuracy: 0.5385\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 93.8803 - accuracy: 0.5161 - val_loss: 7.5427 - val_accuracy: 0.5385\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 107.4208 - accuracy: 0.4903 - val_loss: 7.8555 - val_accuracy: 0.5385\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 114.9655 - accuracy: 0.4581 - val_loss: 7.7268 - val_accuracy: 0.5385\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 90.9144 - accuracy: 0.5097 - val_loss: 7.6459 - val_accuracy: 0.5385\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 84.9725 - accuracy: 0.5806 - val_loss: 7.1498 - val_accuracy: 0.5385\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 88.9208 - accuracy: 0.5226 - val_loss: 7.3956 - val_accuracy: 0.5385\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 96.5073 - accuracy: 0.5484 - val_loss: 7.5572 - val_accuracy: 0.5385\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 108.0187 - accuracy: 0.5032 - val_loss: 7.5244 - val_accuracy: 0.5385\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 93.5065 - accuracy: 0.5484 - val_loss: 7.5029 - val_accuracy: 0.5385\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 110.8171 - accuracy: 0.4903 - val_loss: 7.8821 - val_accuracy: 0.5385\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 109.1183 - accuracy: 0.4645 - val_loss: 7.6022 - val_accuracy: 0.5385\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 111.6398 - accuracy: 0.4903 - val_loss: 7.9586 - val_accuracy: 0.5385\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 78.8730 - accuracy: 0.5677 - val_loss: 8.6541 - val_accuracy: 0.5385\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 82.9821 - accuracy: 0.6000 - val_loss: 8.2297 - val_accuracy: 0.5385\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 98.9442 - accuracy: 0.4581 - val_loss: 7.9259 - val_accuracy: 0.5385\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 100.0930 - accuracy: 0.5226 - val_loss: 7.2789 - val_accuracy: 0.5385\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 91.3975 - accuracy: 0.4903 - val_loss: 7.9610 - val_accuracy: 0.5385\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 89.1256 - accuracy: 0.5290 - val_loss: 8.3230 - val_accuracy: 0.5385\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 85.8003 - accuracy: 0.5032 - val_loss: 8.6759 - val_accuracy: 0.5385\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 91.0723 - accuracy: 0.5677 - val_loss: 8.1915 - val_accuracy: 0.5385\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 95.7784 - accuracy: 0.4903 - val_loss: 7.9726 - val_accuracy: 0.5385\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 110.4135 - accuracy: 0.4323 - val_loss: 8.0624 - val_accuracy: 0.5385\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 105.1656 - accuracy: 0.4839 - val_loss: 8.0045 - val_accuracy: 0.5385\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 92.3354 - accuracy: 0.4968 - val_loss: 8.1092 - val_accuracy: 0.5385\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 86.7915 - accuracy: 0.4903 - val_loss: 7.6897 - val_accuracy: 0.5385\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 98.9736 - accuracy: 0.4968 - val_loss: 7.4940 - val_accuracy: 0.5385\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 91.7936 - accuracy: 0.5742 - val_loss: 7.7269 - val_accuracy: 0.5385\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 76.2815 - accuracy: 0.5806 - val_loss: 7.0127 - val_accuracy: 0.5385\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 90.3583 - accuracy: 0.4645 - val_loss: 7.2891 - val_accuracy: 0.5385\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 93.2731 - accuracy: 0.4452 - val_loss: 7.9880 - val_accuracy: 0.5385\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 88.0392 - accuracy: 0.5613 - val_loss: 8.3227 - val_accuracy: 0.5385\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 83.7759 - accuracy: 0.4516 - val_loss: 8.3484 - val_accuracy: 0.5385\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 75.3004 - accuracy: 0.5355 - val_loss: 8.1951 - val_accuracy: 0.5385\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 74.5680 - accuracy: 0.5806 - val_loss: 7.8465 - val_accuracy: 0.5385\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 91.9997 - accuracy: 0.5161 - val_loss: 8.2901 - val_accuracy: 0.5385\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 89.0293 - accuracy: 0.5742 - val_loss: 8.4698 - val_accuracy: 0.5385\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 81.6561 - accuracy: 0.5806 - val_loss: 8.9144 - val_accuracy: 0.5385\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 86.3516 - accuracy: 0.5097 - val_loss: 8.9546 - val_accuracy: 0.5385\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 74.3944 - accuracy: 0.5032 - val_loss: 8.8443 - val_accuracy: 0.5385\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 64.8756 - accuracy: 0.6065 - val_loss: 8.1274 - val_accuracy: 0.5385\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 81.8383 - accuracy: 0.5613 - val_loss: 8.5021 - val_accuracy: 0.5385\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 98.5879 - accuracy: 0.5161 - val_loss: 8.3016 - val_accuracy: 0.5385\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 83.2485 - accuracy: 0.4710 - val_loss: 8.3923 - val_accuracy: 0.5385\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 76.6378 - accuracy: 0.5226 - val_loss: 8.3373 - val_accuracy: 0.5385\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 90.9784 - accuracy: 0.5161 - val_loss: 8.3164 - val_accuracy: 0.5385\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 82.8781 - accuracy: 0.5032 - val_loss: 8.1560 - val_accuracy: 0.5385\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 82.5342 - accuracy: 0.5484 - val_loss: 8.7848 - val_accuracy: 0.5385\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 76.5037 - accuracy: 0.5161 - val_loss: 9.0291 - val_accuracy: 0.5385\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 75.3207 - accuracy: 0.5548 - val_loss: 9.0753 - val_accuracy: 0.5385\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 94.7026 - accuracy: 0.4581 - val_loss: 9.3001 - val_accuracy: 0.5385\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 83.3437 - accuracy: 0.4323 - val_loss: 9.3733 - val_accuracy: 0.5385\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 91.3711 - accuracy: 0.4452 - val_loss: 9.5085 - val_accuracy: 0.5385\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 83.7843 - accuracy: 0.5290 - val_loss: 10.1407 - val_accuracy: 0.5385\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 69.9403 - accuracy: 0.5419 - val_loss: 10.5474 - val_accuracy: 0.5385\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 85.0042 - accuracy: 0.4710 - val_loss: 11.0110 - val_accuracy: 0.5385\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 64.7114 - accuracy: 0.5806 - val_loss: 10.8908 - val_accuracy: 0.5385\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 107.9956 - accuracy: 0.3871 - val_loss: 11.1126 - val_accuracy: 0.5385\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 76.2406 - accuracy: 0.4710 - val_loss: 11.2375 - val_accuracy: 0.5385\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 80.4679 - accuracy: 0.5097 - val_loss: 11.4522 - val_accuracy: 0.5385\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 70.4400 - accuracy: 0.5290 - val_loss: 11.7857 - val_accuracy: 0.5385\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 89.0679 - accuracy: 0.4323 - val_loss: 11.7818 - val_accuracy: 0.5385\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 72.1649 - accuracy: 0.5290 - val_loss: 12.0053 - val_accuracy: 0.5385\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 68.1453 - accuracy: 0.5161 - val_loss: 12.0390 - val_accuracy: 0.5385\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 77.4358 - accuracy: 0.5419 - val_loss: 12.2477 - val_accuracy: 0.5385\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 78.0833 - accuracy: 0.5355 - val_loss: 12.4300 - val_accuracy: 0.5385\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 91.0540 - accuracy: 0.5161 - val_loss: 12.5367 - val_accuracy: 0.5385\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 78.3876 - accuracy: 0.5097 - val_loss: 13.0685 - val_accuracy: 0.5385\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 80.3603 - accuracy: 0.5613 - val_loss: 13.1344 - val_accuracy: 0.5385\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 70.0946 - accuracy: 0.5871 - val_loss: 13.5280 - val_accuracy: 0.5385\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Test Accuracy:  0.5510204081632653\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.55      1.00      0.71        27\n",
      "\n",
      "    accuracy                           0.55        49\n",
      "   macro avg       0.28      0.50      0.36        49\n",
      "weighted avg       0.30      0.55      0.39        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isvan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\isvan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\isvan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"Test Accuracy: \", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8263bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
    "\n",
    "class CustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.dense2 = Dense(32, activation='relu')\n",
    "        self.dropout2 = Dropout(0.5)\n",
    "        self.output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = CustomModel()\n",
    "model.compile(optimizer='adam',  # Use Adam optimizer\n",
    "              loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6eedf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 60ms/step - loss: 142.2231 - accuracy: 0.5355 - val_loss: 13.5889 - val_accuracy: 0.4615\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 116.8539 - accuracy: 0.5419 - val_loss: 16.9977 - val_accuracy: 0.4615\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 116.1178 - accuracy: 0.5161 - val_loss: 11.7749 - val_accuracy: 0.4615\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 124.2184 - accuracy: 0.4710 - val_loss: 9.3702 - val_accuracy: 0.4615\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 98.6839 - accuracy: 0.5419 - val_loss: 6.0677 - val_accuracy: 0.4615\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 84.8861 - accuracy: 0.5290 - val_loss: 5.8258 - val_accuracy: 0.4615\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 75.6530 - accuracy: 0.5419 - val_loss: 5.8592 - val_accuracy: 0.4615\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 97.5180 - accuracy: 0.4194 - val_loss: 5.9040 - val_accuracy: 0.4615\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 73.5897 - accuracy: 0.5290 - val_loss: 6.7350 - val_accuracy: 0.4615\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 57.2677 - accuracy: 0.5742 - val_loss: 5.1353 - val_accuracy: 0.4615\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 50.3848 - accuracy: 0.4710 - val_loss: 2.9396 - val_accuracy: 0.4615\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 72.6150 - accuracy: 0.5161 - val_loss: 1.0509 - val_accuracy: 0.5385\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43.0888 - accuracy: 0.5613 - val_loss: 0.8453 - val_accuracy: 0.5385\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.5612 - accuracy: 0.4645 - val_loss: 1.2798 - val_accuracy: 0.5385\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 32.0905 - accuracy: 0.4774 - val_loss: 2.1791 - val_accuracy: 0.5385\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.0205 - accuracy: 0.4387 - val_loss: 2.8760 - val_accuracy: 0.5385\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 38.4448 - accuracy: 0.4774 - val_loss: 2.8369 - val_accuracy: 0.5385\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.7125 - accuracy: 0.4839 - val_loss: 2.1600 - val_accuracy: 0.5385\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 31.3590 - accuracy: 0.5290 - val_loss: 2.0720 - val_accuracy: 0.5385\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.3881 - accuracy: 0.5226 - val_loss: 2.0306 - val_accuracy: 0.5385\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 28.8808 - accuracy: 0.5290 - val_loss: 2.1050 - val_accuracy: 0.5385\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 21.6750 - accuracy: 0.5484 - val_loss: 1.6730 - val_accuracy: 0.5385\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 24.4597 - accuracy: 0.4903 - val_loss: 1.4611 - val_accuracy: 0.5385\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 24.3711 - accuracy: 0.5419 - val_loss: 1.2909 - val_accuracy: 0.5385\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 21.4699 - accuracy: 0.5290 - val_loss: 1.1474 - val_accuracy: 0.5385\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.4985 - accuracy: 0.5226 - val_loss: 1.1884 - val_accuracy: 0.5385\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 20.1044 - accuracy: 0.5742 - val_loss: 1.3339 - val_accuracy: 0.5385\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 13.5370 - accuracy: 0.4968 - val_loss: 1.3952 - val_accuracy: 0.5385\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 15.6521 - accuracy: 0.5097 - val_loss: 1.3049 - val_accuracy: 0.5385\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 12.4593 - accuracy: 0.5032 - val_loss: 1.1538 - val_accuracy: 0.5385\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 19.1005 - accuracy: 0.5677 - val_loss: 1.0485 - val_accuracy: 0.5385\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.2911 - accuracy: 0.5871 - val_loss: 0.9230 - val_accuracy: 0.5385\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.7836 - accuracy: 0.4968 - val_loss: 0.8780 - val_accuracy: 0.5385\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5582 - accuracy: 0.5032 - val_loss: 0.7986 - val_accuracy: 0.5385\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6427 - accuracy: 0.5613 - val_loss: 0.7327 - val_accuracy: 0.5385\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.5421 - accuracy: 0.4839 - val_loss: 0.7413 - val_accuracy: 0.5385\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.6433 - accuracy: 0.4645 - val_loss: 0.7880 - val_accuracy: 0.5385\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.5915 - accuracy: 0.4903 - val_loss: 0.8184 - val_accuracy: 0.5385\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.2818 - accuracy: 0.5290 - val_loss: 0.7603 - val_accuracy: 0.5385\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 10.1738 - accuracy: 0.5742 - val_loss: 0.6919 - val_accuracy: 0.5385\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0935 - accuracy: 0.4516 - val_loss: 0.7010 - val_accuracy: 0.4615\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0755 - accuracy: 0.5677 - val_loss: 0.6896 - val_accuracy: 0.5385\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4586 - accuracy: 0.5097 - val_loss: 0.7146 - val_accuracy: 0.5385\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5887 - accuracy: 0.5290 - val_loss: 0.7182 - val_accuracy: 0.5385\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1042 - accuracy: 0.4903 - val_loss: 0.6919 - val_accuracy: 0.5385\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4251 - accuracy: 0.4903 - val_loss: 0.6991 - val_accuracy: 0.4615\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8261 - accuracy: 0.5355 - val_loss: 0.6909 - val_accuracy: 0.5385\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.1403 - accuracy: 0.4645 - val_loss: 0.6919 - val_accuracy: 0.5385\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8140 - accuracy: 0.5419 - val_loss: 0.7202 - val_accuracy: 0.5385\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7491 - accuracy: 0.5355 - val_loss: 0.6949 - val_accuracy: 0.5385\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4871 - accuracy: 0.4839 - val_loss: 0.6898 - val_accuracy: 0.5385\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9453 - accuracy: 0.5161 - val_loss: 0.6896 - val_accuracy: 0.5385\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7058 - accuracy: 0.5355 - val_loss: 0.7013 - val_accuracy: 0.5385\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7554 - accuracy: 0.5290 - val_loss: 0.6923 - val_accuracy: 0.5385\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5860 - accuracy: 0.5355 - val_loss: 0.6916 - val_accuracy: 0.5385\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3103 - accuracy: 0.4129 - val_loss: 0.6928 - val_accuracy: 0.5385\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3473 - accuracy: 0.4710 - val_loss: 0.7248 - val_accuracy: 0.5385\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3871 - accuracy: 0.4903 - val_loss: 0.6930 - val_accuracy: 0.5385\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2899 - accuracy: 0.4710 - val_loss: 0.6997 - val_accuracy: 0.4615\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.0898 - accuracy: 0.4710 - val_loss: 0.6903 - val_accuracy: 0.5385\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3865 - accuracy: 0.5290 - val_loss: 0.7020 - val_accuracy: 0.5385\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.3212 - accuracy: 0.5742 - val_loss: 0.6945 - val_accuracy: 0.5385\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8911 - accuracy: 0.5484 - val_loss: 0.6967 - val_accuracy: 0.4615\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.7071 - accuracy: 0.4774 - val_loss: 0.6967 - val_accuracy: 0.4615\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0125 - accuracy: 0.5484 - val_loss: 0.6922 - val_accuracy: 0.5385\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6788 - accuracy: 0.4968 - val_loss: 0.6959 - val_accuracy: 0.5385\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7948 - accuracy: 0.4839 - val_loss: 0.6899 - val_accuracy: 0.5385\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5625 - accuracy: 0.5290 - val_loss: 0.6904 - val_accuracy: 0.5385\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5539 - accuracy: 0.5484 - val_loss: 0.6959 - val_accuracy: 0.5385\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7917 - accuracy: 0.5742 - val_loss: 0.7049 - val_accuracy: 0.5385\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3895 - accuracy: 0.5355 - val_loss: 0.7019 - val_accuracy: 0.5385\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9470 - accuracy: 0.5355 - val_loss: 0.6933 - val_accuracy: 0.5385\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5812 - accuracy: 0.4968 - val_loss: 0.6914 - val_accuracy: 0.5385\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3876 - accuracy: 0.5097 - val_loss: 0.6928 - val_accuracy: 0.5385\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6684 - accuracy: 0.5097 - val_loss: 0.6913 - val_accuracy: 0.5385\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0386 - accuracy: 0.4581 - val_loss: 0.6957 - val_accuracy: 0.4615\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3959 - accuracy: 0.5226 - val_loss: 0.6951 - val_accuracy: 0.4615\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8431 - accuracy: 0.5226 - val_loss: 0.6907 - val_accuracy: 0.5385\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3660 - accuracy: 0.5226 - val_loss: 0.6901 - val_accuracy: 0.5385\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4383 - accuracy: 0.5226 - val_loss: 0.6918 - val_accuracy: 0.5385\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8546 - accuracy: 0.5484 - val_loss: 0.6913 - val_accuracy: 0.5385\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8604 - accuracy: 0.5097 - val_loss: 0.6970 - val_accuracy: 0.4615\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2228 - accuracy: 0.5097 - val_loss: 0.6998 - val_accuracy: 0.4615\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2707 - accuracy: 0.5161 - val_loss: 0.7025 - val_accuracy: 0.5385\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6817 - accuracy: 0.5226 - val_loss: 0.6917 - val_accuracy: 0.5385\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7510 - accuracy: 0.5226 - val_loss: 0.7015 - val_accuracy: 0.4615\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2822 - accuracy: 0.5742 - val_loss: 0.6899 - val_accuracy: 0.5385\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0609 - accuracy: 0.5613 - val_loss: 0.6938 - val_accuracy: 0.5385\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7500 - accuracy: 0.5290 - val_loss: 0.6935 - val_accuracy: 0.5385\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5349 - accuracy: 0.4581 - val_loss: 0.6911 - val_accuracy: 0.5385\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8976 - accuracy: 0.5419 - val_loss: 0.6932 - val_accuracy: 0.5385\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8675 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5385\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5135 - accuracy: 0.4710 - val_loss: 0.6921 - val_accuracy: 0.5385\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3384 - accuracy: 0.5613 - val_loss: 0.6957 - val_accuracy: 0.5385\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2621 - accuracy: 0.5290 - val_loss: 0.6933 - val_accuracy: 0.5385\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5667 - accuracy: 0.5032 - val_loss: 0.6951 - val_accuracy: 0.4615\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8719 - accuracy: 0.5548 - val_loss: 0.6921 - val_accuracy: 0.5385\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8210 - accuracy: 0.5871 - val_loss: 0.6964 - val_accuracy: 0.5385\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8972 - accuracy: 0.5484 - val_loss: 0.6900 - val_accuracy: 0.5385\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4467 - accuracy: 0.5871 - val_loss: 0.6915 - val_accuracy: 0.5385\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Test Accuracy:  0.5510204081632653\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.55      1.00      0.71        27\n",
      "\n",
      "    accuracy                           0.55        49\n",
      "   macro avg       0.28      0.50      0.36        49\n",
      "weighted avg       0.30      0.55      0.39        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isvan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\isvan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\isvan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"Test Accuracy: \", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80480cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
